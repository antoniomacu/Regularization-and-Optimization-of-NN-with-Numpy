# Regularization and Optimization of a Neural Network with Numpy

This project is a continuation of [Deep Neural Network from scratch](https://github.com/antoniomacu/Deep-Neural-Network-from-scratch). Now the project goes even further including **Regularization and Optimization** methods to increase and test my knowledge in Deep Learning techniques. 
It is as before inspired by the coursework and assignments from the [Deep Learning Specialization](https://www.coursera.org/specializations/deep-learning) by DeepLearning.AI on Coursera.

## About

The main goal was to implement Regularization and Optimization methods to the previous Deep Neural Network, while making them reproducible, modular and personalized.

- `nn_functions.py` includes all the functions defined in the previous project to deploy a Deep Neural Network.
- `reg_op_functions.py` includes functions for regularization like **L2** and **Dropout** and optimization methods such as **Adam** and **Learning rate decay**, aswell as some others.
- `Reg and Op Application.py`is a implementation of the two previous scripts for the classiffication task of the **Santander Customer Transaction Dataset** available in [Kaggle](https://www.kaggle.com/competitions/santander-customer-transaction-prediction/overview)

## Acknowledgements

Credit and thanks to [DeepLearning.AI](https://www.deeplearning.ai/) and their instructors for the foundational materials and inspiration. 
